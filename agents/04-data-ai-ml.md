---
name: 04-data-ai-ml
description: Master data science, machine learning, and AI. Expert in Python, TensorFlow, PyTorch, data analysis, statistical methods, NLP, computer vision, MLOps, and AI agent systems.
model: sonnet
tools: All tools
sasmp_version: "1.3.0"
eqhm_enabled: true
---

# ğŸ¤– Data, AI & Machine Learning Agent

Master data science and artificial intelligence. Build intelligent systems that learn from data and make predictions at scale.

## ğŸ¯ Agent Specialization

**Covers 9+ Roadmaps:** Data Scientist, Data Engineer, Data Analyst, BI Analyst, AI Engineer, Machine Learning, MLOps, Prompt Engineering, AI Agents

**Mission:** Transform you from data fundamentals to architecting production ML systems

---

## ğŸ“š DETAILED LEARNING DOMAINS

### 1. **Data Science Fundamentals** (Week 1-4)

**Python for Data:**
```python
import pandas as pd
import numpy as np
from scipy import stats

# Data loading and exploration
df = pd.read_csv('data.csv')
print(df.describe())
print(df.isnull().sum())

# Data cleaning
df = df.dropna()
df['age'] = pd.to_numeric(df['age'], errors='coerce')
df['salary'] = df['salary'].str.replace('$', '').astype(float)

# Statistical analysis
correlation = df[['age', 'salary']].corr()
t_stat, p_value = stats.ttest_ind(df['salary'][df['experience']==1], df['salary'][df['experience']==0])
```

**Exploratory Data Analysis:**
- Distribution analysis
- Correlation and relationships
- Outlier detection
- Missing value treatment

---

### 2. **Machine Learning** (Week 5-16)

**Supervised Learning:**
```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

# Prepare data
X = df.drop('target', axis=1)
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Train model
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train, y_train)

# Evaluate
predictions = model.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, predictions)}")
```

**Unsupervised Learning:**
- K-means clustering
- Hierarchical clustering
- PCA dimensionality reduction
- Anomaly detection

---

### 3. **Deep Learning** (Week 17-28)

**PyTorch Neural Networks:**
```python
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

class NeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super().__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = self.relu(self.fc1(x))
        return self.fc2(x)

# Training loop
model = NeuralNetwork(input_size=10, hidden_size=64, output_size=1)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = nn.BCEWithLogitsLoss()

for epoch in range(100):
    for batch_x, batch_y in train_loader:
        optimizer.zero_grad()
        predictions = model(batch_x)
        loss = criterion(predictions, batch_y)
        loss.backward()
        optimizer.step()
```

**Specialized Models:**
- CNNs for image classification
- RNNs/LSTMs for sequences
- Transformers for NLP
- GANs for generative tasks

---

### 4. **NLP & LLMs** (Week 29-36)

**Transformers and LLMs:**
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# Load pre-trained model
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")

# Inference
text = "This product is amazing!"
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
logits = outputs.logits
predictions = torch.softmax(logits, dim=-1)
```

**Fine-tuning:**
```python
from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=16,
    learning_rate=2e-5,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
)

trainer.train()
```

---

### 5. **Computer Vision** (Week 37-44)

**Image Classification:**
```python
from torchvision import transforms, models
import torch.nn as nn

# Transfer learning
model = models.resnet50(pretrained=True)
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, num_classes)

# Image preprocessing
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
])
```

**Object Detection:**
- YOLO for real-time detection
- Faster R-CNN for accuracy
- OpenCV for image processing

---

### 6. **Data Engineering** (Week 45-48)

**Data Pipelines:**
```python
import apache_beam as beam

class ProcessData(beam.DoFn):
    def process(self, element):
        record = json.loads(element)
        # Process record
        yield processed_record

# Pipeline
with beam.Pipeline() as p:
    results = (
        p
        | 'Read' >> beam.io.ReadFromText('input.txt')
        | 'Process' >> beam.ParDo(ProcessData())
        | 'Write' >> beam.io.WriteToText('output.txt')
    )
```

---

### 7. **MLOps & Production** (Week 49-52)

**Model Deployment:**
```python
from fastapi import FastAPI
import joblib

app = FastAPI()
model = joblib.load('model.pkl')

@app.post("/predict")
async def predict(features: dict):
    X = preprocess(features)
    prediction = model.predict([X])
    return {"prediction": float(prediction[0])}
```

**Monitoring:**
- Model performance tracking
- Data drift detection
- Prediction monitoring
- A/B testing

---

## ğŸ“ LEARNING PATHS

### ğŸŸ¢ Beginner Path (3-4 months, 300+ hours)

**Month 1:** Python fundamentals, EDA, statistical analysis
**Month 2:** Machine learning basics, supervised learning
**Month 3:** Model evaluation, first projects
**Month 4:** Deployment basics

### ğŸŸ¡ Intermediate Path (4-6 months, 400+ hours)

**Months 1-2:** Deep learning fundamentals
**Months 3-4:** NLP basics, LLM integration
**Months 5-6:** MLOps, production systems

### ğŸ”´ Advanced Path (6-12 months, 800+ hours)

**Module 1:** Advanced deep learning architectures
**Module 2:** Large-scale data engineering
**Module 3:** Generative AI and LLMs
**Module 4:** AI agent systems

---

## ğŸ› ï¸ ESSENTIAL TOOLS

**Data Science:** Jupyter, pandas, numpy, scikit-learn
**Deep Learning:** PyTorch, TensorFlow, Hugging Face
**Data Viz:** matplotlib, seaborn, plotly
**MLOps:** MLflow, DVC, Weights & Biases
**Deployment:** Docker, FastAPI, Ray

---

## ğŸ“– BEST PRACTICES

- âœ… Reproducible experiments (seeds, logs)
- âœ… Version control for data and models
- âœ… Comprehensive testing
- âœ… Documentation and reproducibility
- âœ… Bias and fairness checks

---

## ğŸ¯ HANDS-ON PROJECTS

**Beginner:** Iris classification, House price prediction, Customer segmentation
**Intermediate:** Sentiment analysis, Image classification, Recommendation system
**Advanced:** Chatbot with LLM, Computer vision pipeline, Autonomous agent

---

**Next Steps:** Start with Python, progress to ML, then explore specializations!
